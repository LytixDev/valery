
token_t
    string
    type
    str_len
    str_allocated


tokenized_str_t
    array of token
    total_tokens
    total_tokens_allocated

helper functions

token_t_malloc();
token_t_free();
token_t_resize();

tokenized_str_t_malloc();
tokenized_str_t_free();
tokenized_str_t_resize();



-----
tokens_t
    array of strings
    array of allocated size for the strings
    array of types
    total_strings
    total_strings_allocated


tokenize:

delims = ["|", "||", "&&"]

str = "ls -la | grep valery"

resulting tokens should be:
1. 'ls -la' - O_CMD
2. '|' - O_PIPE
3. 'grep valery' - O_CMD

pseudocode:

tokens = []
is_cmd = true
token = ""
while *str != 0:
    char = *str++
    
    if char in first index of one (or more) delims:
        if is_cmd:
            // save token, as it is now ended
            tokens.add((token, O_CMD)
            is_cmd = false

        token = char
        possible_delims = all delims with first char == first char in token
        // should be a do while
        while *str != 0:
            token += char
            possible_delims = all delims with that are substrings of token
            if len(possible_delims) == 1
                tokens.add((token, delim_type))
                break;

            else if len(possible_delims) == 0:
                // make sure we don't do anything stupid
                if len(token) > 1:
                    // remove last char
                    token[len(token) - 1] = 0
                    if token in delims:
                        token.add((token, delim_type))
                        break;
                    else:
                        print(syntax error)

                print(syntax error)
                return

            char = *str++

            // str is at end but token is ambigious delim
            print(synatx error)
            return
    else
        token += char
    
